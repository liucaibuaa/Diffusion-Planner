{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from nuplan.common.actor_state.vehicle_parameters import get_pacifica_parameters\n",
    "from nuplan.common.actor_state.state_representation import Point2D\n",
    "from nuplan.planning.scenario_builder.nuplan_db.nuplan_scenario_utils import ScenarioMapping\n",
    "from nuplan.planning.scenario_builder.nuplan_db.nuplan_scenario_builder import NuPlanScenarioBuilder\n",
    "from nuplan.planning.scenario_builder.scenario_filter import ScenarioFilter\n",
    "from nuplan.planning.utils.multithreading.worker_parallel import SingleMachineParallelExecutor\n",
    "from nuplan.planning.utils.multithreading.worker_pool import Task\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from diffusion_planner.data_process.roadblock_utils import route_roadblock_correction\n",
    "from diffusion_planner.data_process.agent_process import (\n",
    "agent_past_process,\n",
    "sampled_tracked_objects_to_array_list,\n",
    "sampled_static_objects_to_array_list\n",
    ")\n",
    "from diffusion_planner.data_process.map_process import get_neighbor_vector_set_map, map_process\n",
    "from diffusion_planner.data_process.utils import (convert_to_model_inputs,\n",
    "get_scenario_map,\n",
    "get_filter_parameters,\n",
    "sampled_tracked_objects_to_tensor_list,\n",
    "sampled_tracked_objects_to_tensor\n",
    ")\n",
    "from nuplan.common.actor_state.tracked_objects_types import TrackedObjectType\n",
    "from diffusion_planner.data_process.utils import convert_absolute_quantities_to_relative,_global_state_se2_array_to_local,_global_velocity_to_local\n",
    "from nuplan.planning.training.preprocessing.utils.agents_preprocessing import (\n",
    "    AgentInternalIndex,\n",
    "    EgoInternalIndex,\n",
    "    sampled_past_ego_states_to_tensor,\n",
    "    sampled_past_timestamps_to_tensor,\n",
    "    compute_yaw_rate_from_state_tensors,\n",
    "    filter_agents_tensor,\n",
    "    pack_agents_tensor,\n",
    "    pad_agent_states\n",
    ")\n",
    "import os, torch\n",
    "\n",
    "from diffusion_planner.model.diffusion_utils.sde import SDE, VPSDE_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0870, 0.5941, 0.4159])\n",
      "torch.Size([3, 20, 4]) tensor([[[0.2838]],\n",
      "\n",
      "        [[0.9858]],\n",
      "\n",
      "        [[0.9102]]])\n",
      "torch.Size([3, 20, 4])\n",
      "torch.Size([3, 1, 1])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "traj = np.random.rand(3, 20, 4)  # NumPy 数组\n",
    "traj = torch.tensor(traj, dtype=torch.float32)  # 转换为 PyTorch 张量\n",
    "# print(traj.shape)\n",
    "t = torch.rand(traj.shape[0])\n",
    "print(t)\n",
    "# t = torch.tensor(t, dtype=torch.float32)  # 转换为 PyTorch 标量\n",
    "\n",
    "sde_1 = VPSDE_linear()\n",
    "mean, std = sde_1.marginal_prob(traj, t)  # 现在不会报错\n",
    "\n",
    "print(mean.shape, std)\n",
    "\n",
    "nosie = torch.randn_like(traj)\n",
    "print(nosie.shape)\n",
    "print(std.shape)\n",
    "noisy_traj = mean + std*nosie\n",
    "theta_norm = torch.sqrt(noisy_traj[:,:,2]**2 + noisy_traj[:,:,3]**2 + 1e-6)\n",
    "noisy_traj[:,:,2] /= theta_norm\n",
    "noisy_traj[:,:,3] /= theta_norm\n",
    "print(type(noisy_traj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_planner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
