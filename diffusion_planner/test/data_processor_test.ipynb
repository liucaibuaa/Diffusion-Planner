{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from data_process.data_processor import DataProcessor\n",
    "from nuplan.common.actor_state.state_representation import Point2D\n",
    "from nuplan.planning.scenario_builder.nuplan_db.nuplan_scenario_utils import ScenarioMapping\n",
    "from nuplan.planning.scenario_builder.nuplan_db.nuplan_scenario_builder import NuPlanScenarioBuilder\n",
    "from nuplan.planning.scenario_builder.scenario_filter import ScenarioFilter\n",
    "from nuplan.planning.utils.multithreading.worker_parallel import SingleMachineParallelExecutor\n",
    "from diffusion_planner.data_process.utils import (\n",
    "get_scenario_map,\n",
    "get_filter_parameters,\n",
    "sampled_tracked_objects_to_tensor,\n",
    ")\n",
    "\n",
    "from diffusion_planner.data_process.roadblock_utils import (\n",
    "  route_roadblock_correction\n",
    ")\n",
    "\n",
    "\n",
    "from diffusion_planner.data_process.agent_process import(sampled_tracked_objects_to_array_list,\n",
    "                                                         sampled_static_objects_to_array_list,\n",
    "                                                         agent_past_process,)\n",
    "from diffusion_planner.data_process.map_process import(map_process,\n",
    "                                                       get_neighbor_vector_set_map)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker threads: 128\n"
     ]
    }
   ],
   "source": [
    "db_path = \"/cailiu2/Diffusion-Planner/data/2021.10.21.14.43.30_veh-28_01244_01519.db\" # single db file\n",
    "db_path = \"/share/data_cold/open_data/nuplan/data/cache/mini\"  # mini db files\n",
    "\n",
    "map_path = \"/share/data_cold/open_data/nuplan/maps\"\n",
    "save_path = \"/cailiu2/Diffusion-Planner/data/processed\"\n",
    "map_version = \"nuplan-maps-v1.0\"\n",
    "\n",
    "save_processed_path = \"/cailiu2/Diffusion-Planner/data/processed\"\n",
    "total_scenarios = 10\n",
    "device = torch.device(\"cuda:0\")\n",
    "scenario_mapping = ScenarioMapping(scenario_map=get_scenario_map(), subsample_ratio_override=0.5)\n",
    "builder = NuPlanScenarioBuilder(db_path, map_path, None, None, map_version, scenario_mapping = scenario_mapping)\n",
    "worker = SingleMachineParallelExecutor(use_process_pool=True)\n",
    "scenario_filter = ScenarioFilter(*get_filter_parameters(num_scenarios_per_type=30000,\n",
    "                                                          limit_total_scenarios=total_scenarios))\n",
    "scenarios = builder.get_scenarios(scenario_filter, worker)\n",
    "del worker, builder, scenario_filter\n",
    "processor = DataProcessor(scenarios, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 7])\n"
     ]
    }
   ],
   "source": [
    "from nuplan.planning.training.preprocessing.utils.agents_preprocessing import(sampled_past_ego_states_to_tensor)\n",
    "\"\"\"\n",
    "ego past\n",
    "\"\"\"\n",
    "processor.scenario = scenarios[0]\n",
    "processor.anchor_ego_state = processor.scenario.initial_ego_state\n",
    "\n",
    "past_ego_states = processor.scenario.get_ego_past_trajectory(\n",
    "    iteration=0, num_samples=processor.num_past_poses, time_horizon=processor.past_time_horizon\n",
    ")\n",
    "\n",
    "sampled_past_ego_states = list(past_ego_states) + [processor.anchor_ego_state]\n",
    "past_ego_states_tensor = sampled_past_ego_states_to_tensor(sampled_past_ego_states)\n",
    "print(past_ego_states_tensor.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 7])\n",
      "tensor([ 3.3096e+05,  4.6911e+06,  5.4388e-01, -2.7254e-03,  7.0212e-04,\n",
      "        -4.4483e-02,  1.1129e-02])\n",
      "tensor([ 3.3096e+05,  4.6911e+06,  5.4387e-01, -2.3384e-03,  2.3940e-05,\n",
      "         1.2597e-02,  1.2770e-02])\n",
      "tensor([ 3.3096e+05,  4.6911e+06,  5.4387e-01, -6.4551e-03, -5.3419e-04,\n",
      "        -1.2633e-02, -3.7846e-03])\n",
      "tensor([ 3.3096e+05,  4.6911e+06,  5.4395e-01, -7.3130e-03,  5.7190e-05,\n",
      "        -7.4196e-02, -8.6003e-03])\n"
     ]
    }
   ],
   "source": [
    "processor = DataProcessor(scenarios, device)\n",
    "processor.scenario = scenarios[0]\n",
    "\"\"\"\n",
    "ego future\n",
    "\"\"\"\n",
    "future_ego_states = processor.scenario.get_ego_future_trajectory(iteration=0, num_samples=processor.num_future_poses, time_horizon= processor.future_time_horizon)\n",
    "future_ego_states_tensor = sampled_past_ego_states_to_tensor(list(future_ego_states))\n",
    "print(future_ego_states_tensor.shape)\n",
    "print(future_ego_states_tensor[0])\n",
    "print(past_ego_states_tensor[-1])\n",
    "print(past_ego_states_tensor[-2])\n",
    "print(past_ego_states_tensor[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "neighbors = processor.scenario.initial_tracked_objects\n",
    "neighbor_past = list(processor.scenario.get_past_tracked_objects(iteration= 0, time_horizon=2.0, num_samples = 10 * 2))\n",
    "track_objs = neighbor_past[0].tracked_objects # center, track_token\n",
    "print(len(track_objs))\n",
    "\n",
    "neighbor_future = list(processor.scenario.get_future_tracked_objects(iteration= 0, time_horizon=5.0, num_samples = 10 * 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tracked_objects(tracked_objects_in_all_frames, full_time_horizon: int):\n",
    "\n",
    "  # 创建一个字典来存储所有障碍物的轨迹\n",
    "  object_trajectories = {}\n",
    "\n",
    "  # 遍历每一帧的 tracked_objects\n",
    "  for frame_idx, detection_frame in enumerate(tracked_objects_in_all_frames):\n",
    "      for obj in detection_frame.tracked_objects:\n",
    "          obj_token = obj.track_token  # 获取障碍物 ID\n",
    "          obj_position = np.array([obj.center.x, obj.center.y])  # 获取障碍物位置 (x, y)\n",
    "\n",
    "          # 如果该障碍物 ID 还未存储，则初始化\n",
    "          if obj_token not in object_trajectories:\n",
    "              object_trajectories[obj_token] = []\n",
    "\n",
    "          # 记录该障碍物在该帧的位置信息\n",
    "          object_trajectories[obj_token].append(obj_position)\n",
    "\n",
    "  # 统一轨迹长度，填充 NaN\n",
    "  for obj_token, traj in object_trajectories.items():\n",
    "      traj = np.array(traj)  # 转换为 NumPy 数组，形状为 (N, 2)\n",
    "      num_frames = traj.shape[0]\n",
    "\n",
    "      if num_frames < full_time_horizon:\n",
    "          # 如果轨迹长度小于 V，则用 NaN 填充\n",
    "          pad_size = full_time_horizon - num_frames\n",
    "          pad_array = np.full((pad_size, 2), np.nan)  # 生成 (pad_size, 2) 的 NaN 数组\n",
    "          object_trajectories[obj_token] = np.vstack([traj, pad_array])  # 拼接填充\n",
    "      else:\n",
    "          # 如果轨迹长度大于 V，则裁剪\n",
    "          object_trajectories[obj_token] = traj[:full_time_horizon]\n",
    "\n",
    "  return object_trajectories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_traj = process_tracked_objects(neighbor_past, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 完整文件路径\u001b[39;00m\n\u001b[1;32m     16\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_path, file_name)\n\u001b[0;32m---> 17\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mdata\u001b[49m, file_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 处理时间格式\n",
    "\n",
    "save_path = \"/cailiu2/Diffusion-Planner/data/processed\"\n",
    "# 生成文件名\n",
    "file_name = f\"{processor.scenario.log_name}_{processor.scenario.token}_{processor.scenario.scenario_type}.pt\"\n",
    "\n",
    "# 确保文件名合法（移除特殊字符）\n",
    "file_name = file_name.replace(\":\", \"_\").replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "\n",
    "# 指定存放路径\n",
    "os.makedirs(save_path, exist_ok=True)  # 确保目录存在\n",
    "\n",
    "# 完整文件路径\n",
    "file_path = os.path.join(save_path, file_name)\n",
    "torch.save(data, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1.12.1+cu113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/dlp/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())  # 如果为 True，表示有 CUDA 可用；如果为 False，则没有 CUDA 可用\n",
    "print(torch.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
