{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_planner.data_process.data_processor import DataProcessor\n",
    "from nuplan.common.actor_state.state_representation import Point2D\n",
    "from nuplan.planning.scenario_builder.nuplan_db.nuplan_scenario_utils import ScenarioMapping\n",
    "from nuplan.planning.scenario_builder.nuplan_db.nuplan_scenario_builder import NuPlanScenarioBuilder\n",
    "from nuplan.planning.scenario_builder.scenario_filter import ScenarioFilter\n",
    "from nuplan.planning.utils.multithreading.worker_parallel import SingleMachineParallelExecutor\n",
    "\n",
    "from diffusion_planner.data_process.utils import (\n",
    "get_scenario_map,\n",
    "get_filter_parameters,\n",
    "sampled_tracked_objects_to_tensor,\n",
    ")\n",
    "\n",
    "from diffusion_planner.data_process.roadblock_utils import (\n",
    "  route_roadblock_correction\n",
    ")\n",
    "\n",
    "\n",
    "from diffusion_planner.data_process.agent_process import(sampled_tracked_objects_to_array_list,\n",
    "                                                         sampled_static_objects_to_array_list,\n",
    "                                                         agent_past_process,)\n",
    "from diffusion_planner.data_process.map_process import(map_process,\n",
    "                                                       get_neighbor_vector_set_map)\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker threads: 128\n"
     ]
    }
   ],
   "source": [
    "db_path = \"/cailiu2/Diffusion-Planner/data/2021.10.21.14.43.30_veh-28_01244_01519.db\" # single db file\n",
    "db_path = \"/share/data_cold/open_data/nuplan/data/cache/mini\"  # mini db files\n",
    "\n",
    "map_path = \"/share/data_cold/open_data/nuplan/maps\"\n",
    "save_path = \"/cailiu2/Diffusion-Planner/data/processed\"\n",
    "map_version = \"nuplan-maps-v1.0\"\n",
    "\n",
    "save_processed_path = \"/cailiu2/Diffusion-Planner/data/processed\"\n",
    "total_scenarios = 10\n",
    "scenario_mapping = ScenarioMapping(scenario_map=get_scenario_map(), subsample_ratio_override=0.5)\n",
    "builder = NuPlanScenarioBuilder(db_path, map_path, None, None, map_version, scenario_mapping = scenario_mapping)\n",
    "worker = SingleMachineParallelExecutor(use_process_pool=True)\n",
    "scenario_filter = ScenarioFilter(*get_filter_parameters(num_scenarios_per_type=30000,\n",
    "                                                          limit_total_scenarios=total_scenarios))\n",
    "scenarios = builder.get_scenarios(scenario_filter, worker)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "del worker, builder, scenario_filter\n",
    "processor = DataProcessor(scenarios,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_planner.data_process.utils import convert_absolute_quantities_to_relative,_global_state_se2_array_to_local,_global_velocity_to_local\n",
    "from nuplan.planning.training.preprocessing.utils.agents_preprocessing import EgoInternalIndex, AgentInternalIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1, 11)\n",
      "(30, 80, 11)\n"
     ]
    }
   ],
   "source": [
    "from nuplan.common.actor_state.tracked_objects_types import TrackedObjectType\n",
    "scenario = processor._scenarios[0]\n",
    "map_name = scenario._map_name\n",
    "token = scenario.token\n",
    "processor.scenario = scenario\n",
    "processor.map_api = scenario.map_api\n",
    "\n",
    "\"\"\"\n",
    "ego\n",
    "\"\"\"\n",
    "ego_state = processor.scenario.initial_ego_state\n",
    "ego_coords = Point2D(ego_state.rear_axle.x, ego_state.rear_axle.y)\n",
    "anchor_ego_state = np.array([ego_state.rear_axle.x, ego_state.rear_axle.y, ego_state.rear_axle.heading], \\\n",
    "                            dtype=np.float64)\n",
    "\n",
    "\"\"\"\n",
    "neighbor agents\n",
    "\"\"\"\n",
    "neighbors = processor.scenario.initial_tracked_objects\n",
    "neighbor_past = list(processor.scenario.get_past_tracked_objects(iteration= 0, time_horizon=1.0))\n",
    "tracked_objects, tracked_objects_types, tracked_obj_tokens = sampled_tracked_objects_to_tensor(neighbors.tracked_objects)\n",
    "#  tracked_objects_past, _ = sampled_tracked_objects_to_array_list(neighbor_past)\n",
    "static_objects, static_objects_types =sampled_static_objects_to_array_list(neighbor_past[-1])\n",
    "tracked_objects_list = []\n",
    "for tracked_object in tracked_objects:\n",
    "  tracked_objects_list.append(tracked_object)\n",
    "_, neighbor_past, selected_indices, static_objects = agent_past_process(None, tracked_objects, tracked_objects_types, processor.num_agents,\\\n",
    "                                                        static_objects, static_objects_types, \\\n",
    "                                                        processor.num_static, processor.max_ped_bike, anchor_ego_state)\n",
    "# print(selected_indices[12])\n",
    "\n",
    "objects_tokens = [tracked_obj_tokens[key] for key in selected_indices]\n",
    "# print(len(selected_indices))\n",
    "# print(len(objects_tokens))\n",
    "# print(objects_tokens)\n",
    "neighbor_future = list(processor.scenario.get_future_tracked_objects(iteration= 0, time_horizon=8.0, num_samples =int(8*10)))\n",
    "# print(len(neighbor_future))\n",
    "slected_objs_future_traj = np.full((len(neighbor_future), len(objects_tokens), 11), np.nan, dtype=np.float64)\n",
    "for frame_id in range(len(neighbor_future)):\n",
    "  tracked_objects = neighbor_future[frame_id]\n",
    "  all_future_neighbor_info = []\n",
    "  current_frame_tracked_objects = {tracked_object.track_token: tracked_object for tracked_object in tracked_objects.tracked_objects}\n",
    "  for i in range(len(objects_tokens)):\n",
    "    if objects_tokens[i] in current_frame_tracked_objects.keys():\n",
    "      agent_state = current_frame_tracked_objects[objects_tokens[i]]\n",
    "\n",
    "      agent_global_poses = np.array([[agent_state.center.x, agent_state.center.y, agent_state.center.heading]])\n",
    "      agent_global_velocities = np.array([[agent_state.velocity.x, agent_state.velocity.y]])\n",
    "      transformed_poses = _global_state_se2_array_to_local(agent_global_poses, anchor_ego_state)\n",
    "      transformed_velocities = _global_velocity_to_local(agent_global_velocities, anchor_ego_state[-1])\n",
    "      local_agent_state = np.zeros((1, 11))\n",
    "      local_agent_state[:, 0] = transformed_poses[:, 0]\n",
    "      local_agent_state[:, 1] = transformed_poses[:, 1]\n",
    "      local_agent_state[:, 2] = np.cos(transformed_poses[:, 2])\n",
    "      local_agent_state[:, 3] = np.sin(transformed_poses[:, 2])\n",
    "      local_agent_state[:, 4] = transformed_velocities[:, 0]\n",
    "      local_agent_state[:, 5] = transformed_velocities[:, 1]\n",
    "      local_agent_state[:, 6] = agent_state.box.width\n",
    "      local_agent_state[:, 7] = agent_state.box.length\n",
    "      if agent_state.tracked_object_type == TrackedObjectType.VEHICLE:\n",
    "        local_agent_state[:, 8:] = [1, 0, 0]  # Mark as VEHICLE\n",
    "      elif agent_state.tracked_object_type == TrackedObjectType.PEDESTRIAN:\n",
    "        local_agent_state[:, 8:] = [0, 1, 0]  # Mark as PEDESTRIAN\n",
    "      else:  # TrackedObjectType.BICYCLE\n",
    "        local_agent_state[:, 8:] = [0, 0, 1]  # Mark as BICYCLE\n",
    "      slected_objs_future_traj[frame_id, i, :] = local_agent_state\n",
    "# selected_neighbor_future = np.full(len(objects_tokens))\n",
    "slected_objs_future_traj = slected_objs_future_traj.transpose(1, 0, 2)\n",
    "print(neighbor_past.shape)\n",
    "print(slected_objs_future_traj.shape)\n",
    "# neighbor_future.tracked_objects\n",
    "# for token in objects_tokens:\n",
    "#   selected_neighbor_future.append([selected_tracked_object for selected_tracked_object in neighbor_future \\\n",
    "#                                   if selected_tracked_object.tracked_objects.track_token == token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_ego_states = processor.scenario.get_ego_future_trajectory(iteration=0, num_samples=int(8*10), time_horizon= 8.0)\n",
    "future_ego_states_numpy = np.array([(ego_state.rear_axle.x, ego_state.rear_axle.y, ego_state.rear_axle.heading, \\\n",
    "                  ego_state.dynamic_car_state.rear_axle_velocity_2d.x, ego_state.dynamic_car_state.rear_axle_velocity_2d.y,\\\n",
    "                  ego_state.dynamic_car_state.rear_axle_acceleration_2d.x, ego_state.dynamic_car_state.rear_axle_acceleration_2d.y ) for ego_state in future_ego_states], dtype = np.float64)\n",
    "local_future_ego_states = convert_absolute_quantities_to_relative(future_ego_states_numpy, anchor_ego_state,'ego')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_processed_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cailiu2/Diffusion-Planner/diffusion_planner/data_process/data_processor.py:166\u001b[0m, in \u001b[0;36mDataProcessor.work\u001b[0;34m(self, save_dir, debug)\u001b[0m\n\u001b[1;32m    160\u001b[0m _, neighbor_past, selected_indices, static_objects \u001b[38;5;241m=\u001b[39m agent_past_process(\u001b[38;5;28;01mNone\u001b[39;00m, tracked_objects, tracked_objects_types, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_agents,\\\n\u001b[1;32m    161\u001b[0m                                                          static_objects, static_objects_types, \\\n\u001b[1;32m    162\u001b[0m                                                          \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_static, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_ped_bike, anchor_ego_state)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03mselected neighbor future agents\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m objects_tokens \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tracked_obj_tokens \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m selected_indices]\n\u001b[1;32m    167\u001b[0m selected_objects_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(objects_tokens, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m k: np\u001b[38;5;241m.\u001b[39mwhere(selected_indices \u001b[38;5;241m==\u001b[39m tracked_obj_tokens[k])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    169\u001b[0m neighbor_future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscenario\u001b[38;5;241m.\u001b[39mget_future_tracked_objects(iteration\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, time_horizon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture_time_horizon, num_samples \u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_future_poses))\n",
      "File \u001b[0;32m/cailiu2/Diffusion-Planner/diffusion_planner/data_process/data_processor.py:166\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    160\u001b[0m _, neighbor_past, selected_indices, static_objects \u001b[38;5;241m=\u001b[39m agent_past_process(\u001b[38;5;28;01mNone\u001b[39;00m, tracked_objects, tracked_objects_types, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_agents,\\\n\u001b[1;32m    161\u001b[0m                                                          static_objects, static_objects_types, \\\n\u001b[1;32m    162\u001b[0m                                                          \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_static, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_ped_bike, anchor_ego_state)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03mselected neighbor future agents\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m objects_tokens \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tracked_obj_tokens \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m selected_indices]\n\u001b[1;32m    167\u001b[0m selected_objects_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(objects_tokens, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m k: np\u001b[38;5;241m.\u001b[39mwhere(selected_indices \u001b[38;5;241m==\u001b[39m tracked_obj_tokens[k])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    169\u001b[0m neighbor_future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscenario\u001b[38;5;241m.\u001b[39mget_future_tracked_objects(iteration\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, time_horizon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture_time_horizon, num_samples \u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_future_poses))\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "processor.work(save_dir=save_processed_path, debug = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point2D(x=330957.49299200956, y=4691143.579406448)\n",
      "[3.30957493e+05 4.69114358e+06 5.43869085e-01]\n",
      "<class 'list'>\n",
      "<class 'nuplan.planning.simulation.observation.observation_type.DetectionsTracks'>\n",
      "(57, 8)\n",
      "10\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ego\n",
    "\"\"\"\n",
    "ego_state = processor.scenario.initial_ego_state\n",
    "ego_coords = Point2D(ego_state.rear_axle.x, ego_state.rear_axle.y)\n",
    "anchor_ego_state = np.array([ego_state.rear_axle.x, ego_state.rear_axle.y, ego_state.rear_axle.heading], dtype=np.float64)\n",
    "print(ego_coords)\n",
    "print(anchor_ego_state)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "neighbor\n",
    "\"\"\"\n",
    "# neighbor_agent_past, neighbor_agents_types = processor.get_neighbor_agents()\n",
    "neighbors = processor.scenario.initial_tracked_objects\n",
    "neighbors.tracked_objects\n",
    "# print(len(neighbors.tracked_objects))\n",
    "# print(type(neighbors.tracked_objects))\n",
    "\n",
    "neighbor_past = list(processor.scenario.get_past_tracked_objects(iteration= 0, time_horizon=1.0))\n",
    "print(type(neighbor_past))\n",
    "print(type(neighbor_past[0]))\n",
    "# for neighbor in neighbors:\n",
    "tracked_objects, tracked_objects_types = sampled_tracked_objects_to_tensor(neighbors.tracked_objects)\n",
    "tracked_objects_past, _ = sampled_tracked_objects_to_array_list(neighbor_past)\n",
    "static_objects, static_objects_types =sampled_static_objects_to_array_list(neighbor_past[-1])\n",
    "# print(type(neighbor_past))\n",
    "# print(len(neighbor_past))\n",
    "tracked_objects_list = []\n",
    "\n",
    "for tracked_object in tracked_objects:\n",
    "  tracked_objects_list.append(tracked_object)\n",
    "print(tracked_objects_past[0].shape)\n",
    "print(len(tracked_objects_past))\n",
    "print(len(static_objects))\n",
    "\n",
    "num_agents = 30\n",
    "num_statics = 30\n",
    "max_ped_bike = 10\n",
    "_, neighbor_past, _, static_objects = agent_past_process(None, tracked_objects, tracked_objects_types, num_agents,static_objects, static_objects_types, \\\n",
    "                                                          num_statics, max_ped_bike, anchor_ego_state)\n",
    "# print(len(tracked_objects_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Map\n",
    "'''\n",
    "map_api = processor.scenario.map_api\n",
    "route_roadblocks_ids = processor.scenario.get_route_roadblock_ids()\n",
    "\n",
    "route_roadblocks_ids =route_roadblock_correction(\n",
    "                    ego_state, map_api, route_roadblocks_ids\n",
    "                    )\n",
    "traffic_light_data = processor.scenario.get_traffic_light_status_at_iteration(iteration= 0)\n",
    "coords, traffic_light_data, speed_limit, lane_route =get_neighbor_vector_set_map(\n",
    "            map_api, processor._map_features, ego_coords, processor._radius, traffic_light_data)\n",
    "vector_map = map_process(route_roadblocks_ids, anchor_ego_state, coords, traffic_light_data, speed_limit, lane_route, processor._map_features,\n",
    "                            processor._max_elements, processor._max_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"neighbor_agents_past\": neighbor_past[:, -21:],\n",
    "        \"ego_current_state\": np.array([0., 0., 1. ,0.], dtype=np.float32), # ego centric x, y, cos, sin\n",
    "        \"static_objects\": static_objects}\n",
    "data.update(vector_map)\n",
    "import torch\n",
    "from diffusion_planner.data_process.utils import convert_to_model_inputs\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = convert_to_model_inputs(data, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 处理时间格式\n",
    "\n",
    "save_path = \"/cailiu2/Diffusion-Planner/data/processed\"\n",
    "# 生成文件名\n",
    "file_name = f\"{processor.scenario.log_name}_{processor.scenario.token}_{processor.scenario.scenario_type}.pt\"\n",
    "\n",
    "# 确保文件名合法（移除特殊字符）\n",
    "file_name = file_name.replace(\":\", \"_\").replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "\n",
    "# 指定存放路径\n",
    "os.makedirs(save_path, exist_ok=True)  # 确保目录存在\n",
    "\n",
    "# 完整文件路径\n",
    "file_path = os.path.join(save_path, file_name)\n",
    "torch.save(data, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1.12.1+cu113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/dlp/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())  # 如果为 True，表示有 CUDA 可用；如果为 False，则没有 CUDA 可用\n",
    "print(torch.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_planner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
