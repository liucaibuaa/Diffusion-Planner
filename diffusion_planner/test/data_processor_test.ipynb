{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_planner.data_process.data_processor import DataProcessor\n",
    "from nuplan.common.actor_state.state_representation import Point2D\n",
    "from nuplan.planning.scenario_builder.nuplan_db.nuplan_scenario_utils import ScenarioMapping\n",
    "from nuplan.planning.scenario_builder.nuplan_db.nuplan_scenario_builder import NuPlanScenarioBuilder\n",
    "from nuplan.planning.scenario_builder.scenario_filter import ScenarioFilter\n",
    "from nuplan.planning.utils.multithreading.worker_parallel import SingleMachineParallelExecutor\n",
    "\n",
    "from diffusion_planner.data_process.utils import (\n",
    "get_scenario_map,\n",
    "get_filter_parameters,\n",
    "sampled_tracked_objects_to_tensor,\n",
    ")\n",
    "\n",
    "from diffusion_planner.data_process.roadblock_utils import (\n",
    "  route_roadblock_correction\n",
    ")\n",
    "\n",
    "\n",
    "from diffusion_planner.data_process.agent_process import(sampled_tracked_objects_to_array_list,\n",
    "                                                         sampled_static_objects_to_array_list,\n",
    "                                                         agent_past_process,)\n",
    "from diffusion_planner.data_process.map_process import(map_process,\n",
    "                                                       get_neighbor_vector_set_map)\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker threads: 128\n"
     ]
    }
   ],
   "source": [
    "db_path = \"/cailiu2/Diffusion-Planner/data/2021.10.21.14.43.30_veh-28_01244_01519.db\" # single db file\n",
    "db_path = \"/share/data_cold/open_data/nuplan/data/cache/mini\"  # mini db files\n",
    "\n",
    "map_path = \"/share/data_cold/open_data/nuplan/maps\"\n",
    "save_path = \"/cailiu2/Diffusion-Planner/data/processed\"\n",
    "map_version = \"nuplan-maps-v1.0\"\n",
    "\n",
    "save_processed_path = \"/cailiu2/Diffusion-Planner/data/processed\"\n",
    "total_scenarios = 10\n",
    "scenario_mapping = ScenarioMapping(scenario_map=get_scenario_map(), subsample_ratio_override=0.5)\n",
    "builder = NuPlanScenarioBuilder(db_path, map_path, None, None, map_version, scenario_mapping = scenario_mapping)\n",
    "worker = SingleMachineParallelExecutor(use_process_pool=True)\n",
    "scenario_filter = ScenarioFilter(*get_filter_parameters(num_scenarios_per_type=30000,\n",
    "                                                          limit_total_scenarios=total_scenarios))\n",
    "scenarios = builder.get_scenarios(scenario_filter, worker)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "del worker, builder, scenario_filter\n",
    "processor = DataProcessor(scenarios,device)\n",
    "# processor.work(save_path, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_planner.data_process.utils import convert_absolute_quantities_to_relative,_global_state_se2_array_to_local,_global_velocity_to_local\n",
    "from nuplan.planning.training.preprocessing.utils.agents_preprocessing import EgoInternalIndex, AgentInternalIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1, 11)\n",
      "(30, 80, 11)\n"
     ]
    }
   ],
   "source": [
    "from nuplan.common.actor_state.tracked_objects_types import TrackedObjectType\n",
    "scenario = processor._scenarios[0]\n",
    "map_name = scenario._map_name\n",
    "token = scenario.token\n",
    "processor.scenario = scenario\n",
    "processor.map_api = scenario.map_api\n",
    "\n",
    "\"\"\"\n",
    "ego\n",
    "\"\"\"\n",
    "ego_state = processor.scenario.initial_ego_state\n",
    "ego_coords = Point2D(ego_state.rear_axle.x, ego_state.rear_axle.y)\n",
    "anchor_ego_state = np.array([ego_state.rear_axle.x, ego_state.rear_axle.y, ego_state.rear_axle.heading], \\\n",
    "                            dtype=np.float64)\n",
    "\n",
    "\"\"\"\n",
    "neighbor agents\n",
    "\"\"\"\n",
    "neighbors = processor.scenario.initial_tracked_objects\n",
    "neighbor_past = list(processor.scenario.get_past_tracked_objects(iteration= 0, time_horizon=1.0))\n",
    "tracked_objects, tracked_objects_types, tracked_obj_tokens = sampled_tracked_objects_to_tensor(neighbors.tracked_objects)\n",
    "#  tracked_objects_past, _ = sampled_tracked_objects_to_array_list(neighbor_past)\n",
    "static_objects, static_objects_types =sampled_static_objects_to_array_list(neighbor_past[-1])\n",
    "tracked_objects_list = []\n",
    "for tracked_object in tracked_objects:\n",
    "  tracked_objects_list.append(tracked_object)\n",
    "_, neighbor_past, selected_indices, static_objects = agent_past_process(None, tracked_objects, tracked_objects_types, processor.num_agents,\\\n",
    "                                                        static_objects, static_objects_types, \\\n",
    "                                                        processor.num_static, processor.max_ped_bike, anchor_ego_state)\n",
    "# print(selected_indices[12])\n",
    "\n",
    "objects_tokens = [tracked_obj_tokens[key] for key in selected_indices]\n",
    "# print(len(selected_indices))\n",
    "# print(len(objects_tokens))\n",
    "# print(objects_tokens)\n",
    "neighbor_future = list(processor.scenario.get_future_tracked_objects(iteration= 0, time_horizon=8.0, num_samples =int(8*10)))\n",
    "# print(len(neighbor_future))\n",
    "slected_objs_future_traj = np.full((len(neighbor_future), len(objects_tokens), 11), np.nan, dtype=np.float64)\n",
    "for frame_id in range(len(neighbor_future)):\n",
    "  tracked_objects = neighbor_future[frame_id]\n",
    "  all_future_neighbor_info = []\n",
    "  current_frame_tracked_objects = {tracked_object.track_token: tracked_object for tracked_object in tracked_objects.tracked_objects}\n",
    "  for i in range(len(objects_tokens)):\n",
    "    if objects_tokens[i] in current_frame_tracked_objects.keys():\n",
    "      agent_state = current_frame_tracked_objects[objects_tokens[i]]\n",
    "\n",
    "      agent_global_poses = np.array([[agent_state.center.x, agent_state.center.y, agent_state.center.heading]])\n",
    "      agent_global_velocities = np.array([[agent_state.velocity.x, agent_state.velocity.y]])\n",
    "      transformed_poses = _global_state_se2_array_to_local(agent_global_poses, anchor_ego_state)\n",
    "      transformed_velocities = _global_velocity_to_local(agent_global_velocities, anchor_ego_state[-1])\n",
    "      local_agent_state = np.zeros((1, 11))\n",
    "      local_agent_state[:, 0] = transformed_poses[:, 0]\n",
    "      local_agent_state[:, 1] = transformed_poses[:, 1]\n",
    "      local_agent_state[:, 2] = np.cos(transformed_poses[:, 2])\n",
    "      local_agent_state[:, 3] = np.sin(transformed_poses[:, 2])\n",
    "      local_agent_state[:, 4] = transformed_velocities[:, 0]\n",
    "      local_agent_state[:, 5] = transformed_velocities[:, 1]\n",
    "      local_agent_state[:, 6] = agent_state.box.width\n",
    "      local_agent_state[:, 7] = agent_state.box.length\n",
    "      if agent_state.tracked_object_type == TrackedObjectType.VEHICLE:\n",
    "        local_agent_state[:, 8:] = [1, 0, 0]  # Mark as VEHICLE\n",
    "      elif agent_state.tracked_object_type == TrackedObjectType.PEDESTRIAN:\n",
    "        local_agent_state[:, 8:] = [0, 1, 0]  # Mark as PEDESTRIAN\n",
    "      else:  # TrackedObjectType.BICYCLE\n",
    "        local_agent_state[:, 8:] = [0, 0, 1]  # Mark as BICYCLE\n",
    "      slected_objs_future_traj[frame_id, i, :] = local_agent_state\n",
    "# selected_neighbor_future = np.full(len(objects_tokens))\n",
    "slected_objs_future_traj = slected_objs_future_traj.transpose(1, 0, 2)\n",
    "print(neighbor_past.shape)\n",
    "print(slected_objs_future_traj.shape)\n",
    "# neighbor_future.tracked_objects\n",
    "# for token in objects_tokens:\n",
    "#   selected_neighbor_future.append([selected_tracked_object for selected_tracked_object in neighbor_future \\\n",
    "#                                   if selected_tracked_object.tracked_objects.track_token == token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  2.27889064e-17 -2.33842428e-03\n",
      "   2.39401828e-05  1.25967396e-02  1.27703869e-02]]\n",
      "(81, 7)\n",
      "(81, 4)\n"
     ]
    }
   ],
   "source": [
    "future_ego_states = processor.scenario.get_ego_future_trajectory(iteration=0, num_samples=int(8*10), time_horizon= 8.0)\n",
    "future_ego_states_numpy = np.array([(ego_state.rear_axle.x, ego_state.rear_axle.y, ego_state.rear_axle.heading, \\\n",
    "                  ego_state.dynamic_car_state.rear_axle_velocity_2d.x, ego_state.dynamic_car_state.rear_axle_velocity_2d.y,\\\n",
    "                  ego_state.dynamic_car_state.rear_axle_acceleration_2d.x, ego_state.dynamic_car_state.rear_axle_acceleration_2d.y ) for ego_state in future_ego_states], dtype = np.float64)\n",
    "local_future_ego_states = convert_absolute_quantities_to_relative(future_ego_states_numpy, anchor_ego_state,'ego')\n",
    "\n",
    "ego_state_array = np.array([(ego_state.rear_axle.x, ego_state.rear_axle.y, ego_state.rear_axle.heading, \\\n",
    "                  ego_state.dynamic_car_state.rear_axle_velocity_2d.x, ego_state.dynamic_car_state.rear_axle_velocity_2d.y,\\\n",
    "                  ego_state.dynamic_car_state.rear_axle_acceleration_2d.x, ego_state.dynamic_car_state.rear_axle_acceleration_2d.y )], dtype = np.float64)\n",
    "ego_current_states = convert_absolute_quantities_to_relative(ego_state_array,anchor_ego_state,'ego' )\n",
    "future_ego_states_numpy =np.concatenate((ego_current_states,future_ego_states_numpy),axis = 0)\n",
    "future_ego_traj_noise = np.concatenate((\n",
    "    future_ego_states_numpy[:, :2],  # 取前两列 (x, y)\n",
    "    np.cos(future_ego_states_numpy[:, 3:4]),  # 取第三列 (heading) 并计算 cos\n",
    "    np.sin(future_ego_states_numpy[:, 3:4])   # 取第三列 (heading) 并计算 sin\n",
    "), axis=1)\n",
    "print(ego_state_array)\n",
    "print(future_ego_states_numpy.shape)\n",
    "print(future_ego_traj_noise.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_planner.model.diffusion_utils.sde import SDE, VPSDE_linear\n",
    "def add_agent_traj_noise(origin_traj : np.array, sde:SDE, device):\n",
    "    P, T, D = origin_traj.shape # P: agent num， T: frame nums, D: dim\n",
    "    assert D == 4  #x, y, cos, sin\n",
    "    origin_traj_tensor = torch.tensor(origin_traj, dtype=torch.float32).to(device)\n",
    "\n",
    "    t = torch.rand(origin_traj.shape[0])\n",
    "    mean, std = sde.marginal_prob(origin_traj_tensor, t)\n",
    "\n",
    "    noisy_traj = torch.zeros_like(mean)\n",
    "    noisy_traj = mean + std*noisy_traj\n",
    "    theta_norm = torch.sqrt(noisy_traj[:,:,2]**2 + noisy_traj[:,:,3]**2 + 1e-6)\n",
    "    noisy_traj[:,:,2] /= theta_norm\n",
    "    noisy_traj[:,:,3] /= theta_norm\n",
    "\n",
    "    return noisy_traj, t #tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 81, 4)\n",
      "torch.Size([1, 81, 4])\n"
     ]
    }
   ],
   "source": [
    "future_ego_states_numpy = np.array([future_ego_traj_noise])\n",
    "print(future_ego_states_numpy.shape)\n",
    "sde1 = VPSDE_linear()\n",
    "\n",
    "future_ego_noisy_traj,t  = add_agent_traj_noise(future_ego_states_numpy, sde1, device = 'cpu')\n",
    "print(future_ego_noisy_traj.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1, 11)\n",
      "(30, 80, 11)\n",
      "(30, 81, 11)\n",
      "[[ 4.48345613 -4.55687094]\n",
      " [ 4.46854536 -4.54409703]\n",
      " [ 4.45589865 -4.55093455]\n",
      " [ 4.44309554 -4.55699446]\n",
      " [ 4.43011199 -4.56031671]\n",
      " [ 4.41907081 -4.56324914]\n",
      " [ 4.41139103 -4.56506833]\n",
      " [ 4.4052394  -4.56671293]\n",
      " [ 4.40045676 -4.56853253]\n",
      " [ 4.39616283 -4.57039844]\n",
      " [ 4.39325585 -4.57148423]\n",
      " [ 4.39151903 -4.57212056]\n",
      " [ 4.39063017 -4.5723799 ]\n",
      " [ 4.38745016 -4.57131092]\n",
      " [ 4.3856349  -4.57088705]\n",
      " [ 4.38516369 -4.5711056 ]\n",
      " [ 4.38496023 -4.57033664]\n",
      " [ 4.38589158 -4.56975588]\n",
      " [ 4.38632612 -4.56907126]\n",
      " [ 4.38586368 -4.56768715]\n",
      " [ 4.38445494 -4.56639898]\n",
      " [ 4.38078201 -4.56692012]\n",
      " [ 4.37635748 -4.56969109]\n",
      " [ 4.37065359 -4.57008436]\n",
      " [ 4.36396836 -4.56795677]\n",
      " [ 4.35595086 -4.56364245]\n",
      " [ 4.34614005 -4.55661575]\n",
      " [ 4.33506659 -4.54842501]\n",
      " [ 4.32288058 -4.53225092]\n",
      " [ 4.31196398 -4.50479416]\n",
      " [ 4.29989814 -4.46838338]\n",
      " [ 4.28769065 -4.42881649]\n",
      " [ 4.27495557 -4.39013071]\n",
      " [ 4.26232081 -4.340349  ]\n",
      " [ 4.25227572 -4.29786063]\n",
      " [ 4.24637964 -4.2641274 ]\n",
      " [ 4.23951894 -4.23654122]\n",
      " [ 4.23268602 -4.21237315]\n",
      " [ 4.21821574 -4.19027396]\n",
      " [ 4.19890928 -4.17312291]\n",
      " [ 4.18026942 -4.16351547]\n",
      " [ 4.16162157 -4.16002602]\n",
      " [ 4.14147952 -4.16046123]\n",
      " [ 4.12144511 -4.16290049]\n",
      " [ 4.10183411 -4.16580445]\n",
      " [ 4.08341346 -4.16848987]\n",
      " [ 4.06712989 -4.1682471 ]\n",
      " [ 4.05385026 -4.1693627 ]\n",
      " [ 4.04400679 -4.16907893]\n",
      " [ 4.03863499 -4.16830496]\n",
      " [ 4.03713514 -4.17056826]\n",
      " [ 4.03943601 -4.17289154]\n",
      " [ 4.04277302 -4.17461603]\n",
      " [ 4.04578175 -4.17491377]\n",
      " [ 4.05158964 -4.17733788]\n",
      " [ 4.05871226 -4.18094425]\n",
      " [ 4.06523343 -4.18483733]\n",
      " [ 4.06962426 -4.18624202]\n",
      " [ 4.07309833 -4.18712084]\n",
      " [ 4.07656592 -4.18856751]\n",
      " [ 4.08027938 -4.19047016]\n",
      " [ 4.08546649 -4.19260628]\n",
      " [ 4.09054472 -4.1952643 ]\n",
      " [ 4.09426298 -4.20261877]\n",
      " [ 4.09924907 -4.20376659]\n",
      " [ 4.10347899 -4.2120131 ]\n",
      " [ 4.10801082 -4.23098485]\n",
      " [ 4.11196093 -4.25731983]\n",
      " [ 4.11473034 -4.28749235]\n",
      " [ 4.11310501 -4.3198872 ]\n",
      " [ 4.10487576 -4.34451384]\n",
      " [ 4.09118638 -4.3649018 ]\n",
      " [ 4.07748783 -4.3814523 ]\n",
      " [ 4.05872577 -4.3960477 ]\n",
      " [ 4.03828637 -4.404022  ]\n",
      " [ 4.01999206 -4.41290711]\n",
      " [ 4.0030238  -4.4222499 ]\n",
      " [ 3.98827662 -4.43070973]\n",
      " [ 3.97488688 -4.43955147]\n",
      " [ 3.9586282  -4.44927752]\n",
      " [ 3.94528015 -4.45745521]]\n"
     ]
    }
   ],
   "source": [
    "# print(type(local_future_ego_states))\n",
    "# print(local_future_ego_states.shape)\n",
    "# print(local_future_ego_states[0][:2])\n",
    "\n",
    "print(neighbor_past.shape)\n",
    "print(slected_objs_future_traj.shape)\n",
    "slected_objs_future_traj= np.concatenate((neighbor_past, slected_objs_future_traj), axis = 1)\n",
    "\n",
    "# print(slected_objs_future_traj[2, :, :2])\n",
    "# print(slected_objs_future_traj[29, :, :2])\n",
    "# # print(slected_objs_future_traj[10, 1, :2])\n",
    "# # print(slected_objs_future_traj[10, 2, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 81, 11)\n",
      "(30, 81, 4)\n"
     ]
    }
   ],
   "source": [
    "print(slected_objs_future_traj.shape)\n",
    "slected_objs_future_traj = np.concatenate((\n",
    "    slected_objs_future_traj[:,:, :2],  # 取前两列 (x, y)\n",
    "    np.cos(slected_objs_future_traj[:,:, 3:4]),  # 取第三列 (heading) 并计算 cos\n",
    "    np.sin(slected_objs_future_traj[:,:, 3:4])   # 取第三列 (heading) 并计算 sin\n",
    "), axis=2)\n",
    "print(slected_objs_future_traj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 81, 4])\n",
      "torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "future_agent_noisy_traj,t1  = add_agent_traj_noise(slected_objs_future_traj, sde1, device = 'cpu')\n",
    "print(future_agent_noisy_traj.shape)\n",
    "print(t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31])\n"
     ]
    }
   ],
   "source": [
    "result = torch.concat((future_ego_noisy_traj,future_agent_noisy_traj),dim=0 )\n",
    "result_t = torch.concat((t, t1), dim = 0)\n",
    "print(result_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 处理时间格式\n",
    "\n",
    "save_path = \"/cailiu2/Diffusion-Planner/data/processed\"\n",
    "# 生成文件名\n",
    "file_name = f\"{processor.scenario.log_name}_{processor.scenario.token}_{processor.scenario.scenario_type}.pt\"\n",
    "\n",
    "# 确保文件名合法（移除特殊字符）\n",
    "file_name = file_name.replace(\":\", \"_\").replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "\n",
    "# 指定存放路径\n",
    "os.makedirs(save_path, exist_ok=True)  # 确保目录存在\n",
    "\n",
    "# 完整文件路径\n",
    "file_path = os.path.join(save_path, file_name)\n",
    "torch.save(data, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker threads: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataProcessor' object has no attribute 'future_time_horizon'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m processor \u001b[38;5;241m=\u001b[39m DataProcessor(scenarios, device)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cailiu2/Diffusion-Planner/diffusion_planner/data_process/data_processor.py:168\u001b[0m, in \u001b[0;36mwork\u001b[0;34m(self, save_dir, debug)\u001b[0m\n\u001b[1;32m    166\u001b[0m static_objects, static_objects_types \u001b[38;5;241m=\u001b[39msampled_static_objects_to_array_list(neighbor_past[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    167\u001b[0m tracked_objects_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tracked_object \u001b[38;5;129;01min\u001b[39;00m tracked_objects:\n\u001b[1;32m    169\u001b[0m    tracked_objects_list\u001b[38;5;241m.\u001b[39mappend(tracked_object)\n\u001b[1;32m    170\u001b[0m _, neighbor_past, selected_indices, static_objects \u001b[38;5;241m=\u001b[39m agent_past_process(\u001b[38;5;28;01mNone\u001b[39;00m, tracked_objects, tracked_objects_types, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_agents,\\\n\u001b[1;32m    171\u001b[0m                                                          static_objects, static_objects_types, \\\n\u001b[1;32m    172\u001b[0m                                                          \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_static, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_ped_bike, anchor_ego_state)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataProcessor' object has no attribute 'future_time_horizon'"
     ]
    }
   ],
   "source": [
    "map_version = \"nuplan-maps-v1.0\"\n",
    "data_path = \"/share/data_cold/open_data/nuplan/data/cache/mini\"\n",
    "map_path = \"/share/data_cold/open_data/nuplan/maps\"\n",
    "save_path = \"/cailiu2/Diffusion-Planner/data/processed\"\n",
    "total_scenarios = 10\n",
    "scenario_mapping = ScenarioMapping(scenario_map=get_scenario_map(), subsample_ratio_override=0.5)\n",
    "builder = NuPlanScenarioBuilder(data_path, map_path, None, None, map_version, scenario_mapping = scenario_mapping)\n",
    "worker = SingleMachineParallelExecutor(use_process_pool=True, max_workers = 128)\n",
    "scenario_filter = ScenarioFilter(*get_filter_parameters(num_scenarios_per_type=10,\n",
    "                                                          limit_total_scenarios=total_scenarios))\n",
    "scenarios = builder.get_scenarios(scenario_filter, worker)\n",
    "del worker, builder, scenario_filter\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "processor = DataProcessor(scenarios, device)\n",
    "processor.work(save_path, debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_planner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
