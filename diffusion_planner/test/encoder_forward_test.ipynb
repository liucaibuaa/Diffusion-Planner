{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from model.module.utils import DynamicMLP\n",
    "from model.module.utils import DropPath\n",
    "from diffusion_planner.model.module.mixer import MixerBlock\n",
    "\n",
    "from diffusion_planner.model.module.encoder import(\n",
    "  Encoder,SelfAttentionBlock,\n",
    "  AgentFusionEncoder, StaticFusionEncoder,\n",
    "  LaneFusionEncoder, FusionEncoder\n",
    ")\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "  The forward of diffusion planner is:\n",
    "    planner_encoder ---> planner_decoder\n",
    "\n",
    "  planner_encoder: inputs\n",
    "      fusion_encoder( [neighbor_encoder(neighbors) + static_encoder(static) +\\\n",
    "                       lane_encoder(lanes)] + encoding_pos)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from typing import Any\n",
    "class Config:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    hidden_dim: int\n",
    "    agent_num: int\n",
    "    static_objects_num: int\n",
    "    lane_num: int\n",
    "\n",
    "# 加载 YAML 配置文件并转换为 Config 实例\n",
    "def load_config(config_file: str) -> Config:\n",
    "    with open(config_file, 'r') as f:\n",
    "        config_dict = yaml.safe_load(f)  # 解析 YAML 文件\n",
    "    print(type(config_dict))\n",
    "    # 确保返回的是一个字典\n",
    "    if not isinstance(config_dict, dict):\n",
    "        raise ValueError(\"YAML 配置文件解析后应为字典\")\n",
    "\n",
    "    return Config(**config_dict)\n",
    "\n",
    "# 使用配置文件\n",
    "config = load_config('train.yaml')\n",
    "\n",
    "# 访问 config 中的属性\n",
    "print(config.hidden_dim)  # 直接访问 hidden_dim\n",
    "\n",
    "encoder = Encoder(config).to(config.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#whole forward\n",
    "device = torch.device(\"cuda:0\")\n",
    "inputs = torch.load(\"/cailiu2/Diffusion-Planner/diffusion_planner/test/2021.10.01.19.16.42_veh-28_03307_03808_0001593541ec55c3_stationary_in_traffic.pt\", map_location=device)\n",
    "\n",
    "# encoder.forward(inputs)\n",
    "encoder_outputs = {}\n",
    "\n",
    "# agents\n",
    "neighbors = inputs['neighbor_agents_past']\n",
    "\n",
    "# static objects\n",
    "static = inputs['static_objects']\n",
    "\n",
    "# vector maps\n",
    "lanes = inputs['lanes']\n",
    "lanes_speed_limit = inputs['lanes_speed_limit']\n",
    "lanes_has_speed_limit = inputs['lanes_has_speed_limit']\n",
    "\n",
    "B = neighbors.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_neighbors, neighbors_mask, neighbor_pos = encoder.neighbor_encoder(neighbors)\n",
    "encoding_static, static_mask, static_pos = encoder.static_encoder(static)\n",
    "encoding_lanes, lanes_mask, lane_pos = encoder.lane_encoder(lanes, lanes_speed_limit, lanes_has_speed_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 192])\n",
      "torch.Size([1, 30, 192])\n",
      "torch.Size([1, 40, 192])\n",
      "torch.Size([1, 100, 192])\n"
     ]
    }
   ],
   "source": [
    "print(encoding_neighbors.shape)\n",
    "print(encoding_static.shape)\n",
    "print(encoding_lanes.shape)\n",
    "encoding_input = torch.cat([encoding_neighbors, encoding_static, encoding_lanes], dim=1)\n",
    "print(encoding_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 7])\n",
      "torch.Size([1, 30, 7])\n",
      "torch.Size([1, 40, 7])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "print(neighbor_pos.shape)\n",
    "print(static_pos.shape)\n",
    "print(lane_pos.shape)\n",
    "encoding_pos =torch.cat([neighbor_pos, static_pos, lane_pos], dim=1).view(B * encoder.token_num, -1)\n",
    "encoding_mask = torch.cat([neighbors_mask, static_mask, lanes_mask], dim=1).view(-1)\n",
    "print(encoding_mask.shape)\n",
    "encoding_pos = encoder.pos_emb(encoding_pos[~encoding_mask])\n",
    "encoding_pos_result = torch.zeros((B * encoder.token_num, encoder.hidden_dim), device=encoding_pos.device)\n",
    "encoding_pos_result[~encoding_mask] = encoding_pos  # Fill in valid parts\n",
    "encoding_input = encoding_input + encoding_pos_result.view(B, encoder.token_num, -1)\n",
    "encoder_outputs['encoding'] = encoder.fusion(encoding_input, encoding_mask.view(B, encoder.token_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_planner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
