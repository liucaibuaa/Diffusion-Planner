{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from model.module.utils import DynamicMLP\n",
    "from model.module.utils import DropPath\n",
    "from diffusion_planner.model.module.mixer import MixerBlock\n",
    "\n",
    "from diffusion_planner.model.module.decoder import(\n",
    "  Decoder, RouteEncoder,DiT\n",
    ")\n",
    "from diffusion_planner.model.module.encoder import(\n",
    "  Encoder\n",
    ")\n",
    "from diffusion_planner.utils.normalizer import StateNormalizer\n",
    "from diffusion_planner.model.diffusion_utils.sde import SDE, VPSDE_linear\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "class Config:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    hidden_dim: int\n",
    "    agent_num: int\n",
    "    static_objects_num: int\n",
    "    lane_num: int\n",
    "\n",
    "# 加载 YAML 配置文件并转换为 Config 实例\n",
    "def load_config(config_file: str) -> Config:\n",
    "    with open(config_file, 'r') as f:\n",
    "        config_dict = yaml.safe_load(f)  # 解析 YAML 文件\n",
    "    print(type(config_dict))\n",
    "    # 确保返回的是一个字典\n",
    "    if not isinstance(config_dict, dict):\n",
    "        raise ValueError(\"YAML 配置文件解析后应为字典\")\n",
    "\n",
    "    return Config(**config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "config = load_config('train.yaml')\n",
    "\n",
    "# 访问 config 中的属性\n",
    "print(config.hidden_dim)  # 直接访问 hidden_dim\n",
    "\n",
    "encoder = Encoder(config).to(config.device)\n",
    "#whole forward\n",
    "device = torch.device(\"cuda:0\")\n",
    "inputs = torch.load(\"/cailiu2/Diffusion-Planner/diffusion_planner/test/2021.10.01.19.16.42_veh-28_03307_03808_0001593541ec55c3_stationary_in_traffic.pt\", map_location=device)\n",
    "\n",
    "encoder_output = encoder.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(config.state_normalizer['mean'])\n",
    "config.state_normalizer =StateNormalizer(\n",
    "    mean=config.state_normalizer['mean'],\n",
    "    std=config.state_normalizer['std'])\n",
    "decoder = Decoder(config)\n",
    "\n",
    "# decoder.forward(encoder_output, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_current = inputs['ego_current_state'][:, None, :4]\n",
    "neighbors_current = inputs[\"neighbor_agents_past\"][:, :decoder._predicted_neighbor_num, -1, :4]\n",
    "neighbor_current_mask = torch.sum(torch.ne(neighbors_current[..., :4], 0), dim=-1) == 0\n",
    "\n",
    "current_states = torch.cat([ego_current, neighbors_current], dim=1) # [B, P, 4]\n",
    "\n",
    "B, P, _ = current_states.shape\n",
    "assert P == (1 + decoder._predicted_neighbor_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B:  1\n",
      "P:  31\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 30, 1, 11])\n",
      "torch.Size([1, 1, 4])\n",
      "torch.Size([1, 30, 4])\n",
      "torch.Size([1, 31, 4])\n",
      "torch.Size([1, 31, 4])\n"
     ]
    }
   ],
   "source": [
    "ego_neighbor_encoding = encoder_output['encoding']\n",
    "route_lanes = inputs['route_lanes']\n",
    "print(\"B: \", B)\n",
    "print(\"P: \", P)\n",
    "\n",
    "print(inputs['ego_current_state'].shape)\n",
    "print(inputs['neighbor_agents_past'].shape) # x, y, cos h, sin h, vx, vy, length, width，type[3]\n",
    "\n",
    "# inputs['sampled_trajectories'] = inputs['ego_current_state']\n",
    "x = inputs['ego_current_state'].view(B, 1, -1)\n",
    "y= inputs['neighbor_agents_past'][:, :, :, :4]\n",
    "y = y.squeeze(2)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "inputs['sampled_trajectories'] =torch.cat( (x,  y), dim = 1)\n",
    "inputs['diffusion_time'] = 10\n",
    "print(inputs['sampled_trajectories'].shape)\n",
    "inputs['sampled_trajectories'].reshape(B,P,-1)\n",
    "print(inputs['sampled_trajectories'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 31, 4])\n"
     ]
    }
   ],
   "source": [
    "dpr = config.decoder_drop_path_rate\n",
    "dit = DiT(\n",
    "            sde=VPSDE_linear(),\n",
    "            route_encoder = RouteEncoder(config.route_num, config.lane_len, drop_path_rate=config.encoder_drop_path_rate, hidden_dim=config.hidden_dim),\n",
    "            depth=config.decoder_depth,\n",
    "            output_dim= (config.future_len + 1) * 4, # x, y, cos, sin\n",
    "            hidden_dim=config.hidden_dim,\n",
    "            heads=config.num_heads,\n",
    "            dropout=dpr,\n",
    "            model_type=config.diffusion_model_type\n",
    "        ).to(config.device)\n",
    "\n",
    "sample_trajecotries = inputs['sampled_trajectories'].to(config.device)\n",
    "diffusion_time = 10\n",
    "\n",
    "ego_neighbor_encoding = encoder_output['encoding'].to(config.device)\n",
    "route_lanes = inputs['route_lanes'].to(config.device)\n",
    "\n",
    "neighbors_current = inputs[\"neighbor_agents_past\"][:, :config.predicted_neighbor_num, -1, :4].to(config.device)\n",
    "neighbor_current_mask = (torch.sum(torch.ne(neighbors_current[..., :4], 0), dim=-1) == 0).to(config.device)\n",
    "print(inputs['sampled_trajectories'].shape)\n",
    "# score = dit(sample_trajecotries, diffusion_time, ego_neighbor_encoding, route_lanes, neighbor_current_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim =(config.future_len + 1) * 4\n",
    "preproj = DynamicMLP(in_features=output_dim, hidden_features=512, out_features=hidden_dim, drop=0.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_planner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
